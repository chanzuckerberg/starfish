{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starfish BaristaSeq Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "from skimage.transform import SimilarityTransform, warp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import starfish\n",
    "import starfish.data\n",
    "from starfish.spots import SpotFinder\n",
    "from starfish.types import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data for a single field of view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = starfish.data.SeqFISH(use_test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1740/1740 [10:14<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "img = exp['fov_000'].get_image('primary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in BaristaSeq is to do some rough registration. For this data, the rough registration has been done for us by the authors, so it is omitted from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove image background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove image background, BaristaSeq uses a White Tophat filter, which measures the background with a rolling disk morphological element and subtracts it from the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import opening, dilation, disk\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, the background that is being subtracted can be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1954c0198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening = partial(opening, selem=disk(3))\n",
    "\n",
    "# background = img.apply(\n",
    "#     opening,\n",
    "#     group_by={Axes.ROUND, Axes.CH, Axes.ZPLANE}, verbose=False, in_place=False\n",
    "# )\n",
    "\n",
    "# starfish.display(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x195b46748>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wth = starfish.image.Filter.WhiteTophat(masking_radius=3)\n",
    "background_corrected = wth.run(img, in_place=False)\n",
    "starfish.display(background_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale images to equalize spot intensities across channels\n",
    "\n",
    "The number of peaks are not uniform across rounds and channels, which prevents histogram matching across channels. Instead, a percentile value is identified and set as the maximum across channels, and the dynamic range is extended to equalize the channel intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_percentile(data, p=99.9):\n",
    "    data = np.asarray(data)\n",
    "    cval = np.percentile(data, p)\n",
    "    data = data / cval\n",
    "    data[data > 1] = 1\n",
    "    return data\n",
    "\n",
    "scaled = background_corrected.apply(\n",
    "    scale_by_percentile,\n",
    "    group_by={Axes.ROUND, Axes.CH}, verbose=False, in_place=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1b8125630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove residual background\n",
    "\n",
    "The background is fairly uniformly present below intensity=0.5. However, starfish's clip method currently only supports percentiles. To solve this problem, the intensities can be directly edited in the underlying numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "clipped = deepcopy(scaled)\n",
    "clipped.xarray.values[clipped.xarray.values < 0.7] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1b81b0978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Spots\n",
    "\n",
    "Detect spots with a local search blob detector that identifies spots in all rounds and channels and matches them using a local search method. The local search starts in an anchor channel (default ch=1) and identifies the nearest spot in all subsequent imaging rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "lsbd = starfish.spots._detector.local_search_blob_detector.LocalSearchBlobDetector(\n",
    "    min_sigma=(1.5, 1.5, 1.5),\n",
    "    max_sigma=(8, 8, 8),\n",
    "    num_sigma=10,\n",
    "    threshold=threshold,\n",
    "    search_radius=7\n",
    ")\n",
    "intensities = lsbd.run(clipped)\n",
    "decoded = exp.codebook.decode_per_round_max(intensities.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1508e1cf8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped, intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on visual inspection, it looks like the spot correspondence across rounds isn't being detected well. Try the PixelSpotDecoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 971/971 [00:15<00:00, 63.36it/s]\n"
     ]
    }
   ],
   "source": [
    "psd = starfish.spots.PixelSpotDecoder.PixelSpotDecoder(\n",
    "    codebook=exp.codebook, metric='euclidean', distance_threshold=0.5, \n",
    "    magnitude_threshold=0.1, min_area=7, max_area=50\n",
    ")\n",
    "pixel_decoded, ccdr = psd.run(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 280, 280)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdr.label_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajc/projects/spacetx/starfish/starfish/imagestack/imagestack.py:324: UserWarning: ImageStack detected as int64. Converting to float32...\n",
      "  warnings.warn(f\"ImageStack detected as {array.dtype}. Converting to float32...\")\n",
      "/Users/ajc/projects/spacetx/starfish/.venv/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from int64 to float32\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 29/29 [00:00<00:00, 256.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1b90868d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the label image in napari\n",
    "label_image = starfish.ImageStack.from_numpy_array(np.reshape(ccdr.label_image, (1, 1, 29, 280, 280)))\n",
    "starfish.display(label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 911, 923, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941,\n",
       "       942, 943, 944, 945, 946, 947, 948, 949, 950])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ccdr.label_image[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this definitely does not work. It's decoding pixels in subsequent rounds as new unique gene types..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the number of spots being detected by the two spot finders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_decoder spots detected 950\n",
      "local search spot detector spots detected 53\n"
     ]
    }
   ],
   "source": [
    "print(\"pixel_decoder spots detected\", int(np.sum(pixel_decoded['target'] != 'nan')))\n",
    "print(\"local search spot detector spots detected\", int(np.sum(decoded['target'] != 'nan')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the correlation between the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajc/projects/spacetx/starfish/.venv/lib/python3.6/site-packages/scipy/stats/stats.py:3038: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, 1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# get the total counts for each gene from each spot detector\n",
    "pixel_decoded_gene_counts = pd.Series(*np.unique(pixel_decoded['target'], return_counts=True)[::-1])\n",
    "decoded_gene_counts = pd.Series(*np.unique(decoded['target'], return_counts=True)[::-1])\n",
    "\n",
    "# get the genes that are detected by both spot finders\n",
    "codetected = pixel_decoded_gene_counts.index.intersection(decoded_gene_counts.index).drop('nan')\n",
    "\n",
    "# report the correlation\n",
    "pearsonr(pixel_decoded_gene_counts[codetected], decoded_gene_counts[codetected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish",
   "language": "python",
   "name": "starfish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
