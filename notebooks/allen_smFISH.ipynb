{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Allen smFISH results with Starfish\n",
    "\n",
    "This notebook walks through a work flow that reproduces the smFISH result for one field of view using the starfish package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import stats\n",
    "from skimage import (exposure, feature, filters, io, measure,\n",
    "                      morphology, restoration, segmentation, transform,\n",
    "                      util, img_as_float)\n",
    "\n",
    "from starfish.io import Stack\n",
    "from starfish.constants import Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # developer note: for rapid iteration, it may be better to run this cell, download the data once, and load \n",
    "# # the data from the local disk. If so, uncomment this cell and run this instead of the above. \n",
    "# !aws s3 sync s3://czi.starfish.data.public/20180606/allen_smFISH ./allen_smFISH\n",
    "# experiment_json = os.path.abspath(\"./allen_smFISH/fov_001/experiment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a large (1.1GB) FOV, so the download may take some time\n",
    "experiment_json = 'https://dmf0bdeheu4zf.cloudfront.net/20180802/allen_smFISH/fov_001/experiment.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Stack object, which while not well-named right now, should be thought of as an access point to an \"ImageDataSet\". In practice, we expect the Stack object or something similar to it to be an access point for _multiple_ fields of view. In practice, the thing we talk about as a \"TileSet\" is the `Stack.image` object. The data are currently stored in-memory in a `numpy.ndarray`, and that is where most of our operations are done. \n",
    "\n",
    "The numpy array can be accessed through Stack.image.numpy\\_array (public method, read only) or Stack.image.\\_data (read and write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.codebook import Codebook\n",
    "codebook = Codebook.from_json('https://dmf0bdeheu4zf.cloudfront.net/20180802/allen_smFISH/fov_001/codebook.json')\n",
    "codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready now to load the experiment into starfish (This experiment is big, it takes a few minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Stack.from_experiment_json(experiment_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our implemented operations leverage the `Stack.image.apply` method to apply a single function over each of the tiles or volumes in the FOV, depending on whether the method accepts a 2d or 3d array. Below, we're clipping each image independently at the 10th percentile. I've placed the imports next to the methods so that you can easily locate the code, should you want to look under the hood and understand what parameters have been chosen. \n",
    "\n",
    "The verbose flag for our apply loops could use a bit more refinement. We should be able to tell it how many images it needs to process from looking at the image stack, but for now it's dumb so just reports the number of tiles or volumes it's processed. This FOV has 102 images over 3 volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.pipeline.filter import Filter\n",
    "s_clip = Filter.Clip(p_min=10, p_max=100, verbose=True)\n",
    "s_clip.run(s.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still working through the backing of the Stack.image object with the on-disk or on-cloud Tile spec. As a result, most of our methods work in-place. For now, we can hack around this by deepcopying the data before administering the operation. This notebook was developed on a 64gb workstation, so be aware of the memory usage when copying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_backup = deepcopy(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ever want to visualize the image in the notebook, we've added a widget to do that. The first parameter is an indices dict that specifies which imaging round, channel, z-slice you want to view. The result is a pageable visualization across that arbitrary set of slices. Below I'm visualizing the first channel, which your codebook tells me is Nmnt. \n",
    "\n",
    "[N.B. once you click on the slider, you can page with the arrow keys on the keyboard.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.image.show_stack({Indices.CH.value: 0});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bandpass = Filter.Bandpass(lshort=0.5, llong=7, threshold=None, truncate=4, verbose=True)\n",
    "s_bandpass.run(s.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bandpass, there's a point where things get weird, at `c == 0; z <= 14`. In that range the images look mostly like noise. However, _above_ that, they look great + background subtracted! The later stages of the pipeline appear robust to this, though, as no spots are called for the noisy sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wasn't sure if this clipping was supposed to be by volume or tile. I've done tile here, but it can be easily\n",
    "# switched to volume. \n",
    "s_clip = Filter.Clip(p_min=10, p_max=100, is_volume=False, verbose=True)\n",
    "s_clip.run(s.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=(1, 0, 0)  # filter only in z, do nothing in x, y\n",
    "glp = Filter.GaussianLowPass(sigma=sigma, is_volume=True, verbose=True)\n",
    "glp.run(s.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, because spot finding is so slow when single-plex, we'll pilot this on a max projection to show that the parameters work. Here's what trackpy.locate, which we wrap, produces for a z-projection of channel 1. To do use our plotting methods on z-projections we have to expose some of the starfish internals, which will be improved upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from showit import image\n",
    "from trackpy import locate\n",
    "\n",
    "# grab a section from the tensor. \n",
    "ch1 = s.image.max_proj(Indices.Z.value)[0, 1]\n",
    "\n",
    "results = locate(ch1, diameter=3, minmass=250, maxsize=3, separation=5, preprocess=False, percentile=10) \n",
    "results.columns = ['x', 'y', 'intensity', 'r', 'eccentricity', 'signal', 'raw_mass', 'ep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the z-projection\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "ax.imshow(ch1, vmin=15, vmax=52, cmap=plt.cm.gray)\n",
    "\n",
    "# draw called spots on top as red circles\n",
    "# scale radius plots the red circle at scale_radius * spot radius\n",
    "s.image._show_spots(results, ax=plt.gca(), scale_radius=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below spot finding is on the _volumes_ for each channel. This will take about `11m30s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.pipeline.features.spots.detector import SpotFinder\n",
    "\n",
    "# I've guessed at these parameters from the allen_smFISH code, but you might want to tweak these a bit. \n",
    "# as you can see, this function takes a while. It will be great to parallelize this. That's also coming, \n",
    "# although we haven't figured out where it fits in the priority list. \n",
    "kwargs = dict(\n",
    "    spot_diameter=3, # must be odd integer\n",
    "    min_mass=300,\n",
    "    max_size=3,  # this is max _radius_\n",
    "    separation=5,\n",
    "    noise_size=0.65,  # this is not used because preprocess is False\n",
    "    preprocess=False,\n",
    "    percentile=10,  # this is irrelevant when min_mass, spot_diameter, and max_size are set properly\n",
    "    verbose=True,\n",
    "    is_volume=True,\n",
    ")\n",
    "lmpf = SpotFinder.LocalMaxPeakFinder(**kwargs)\n",
    "spot_attributes = lmpf.find(s.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to disk as json\n",
    "for attrs, (round, ch) in spot_attributes:\n",
    "    attrs.save(f'spot_attributes_c{ch}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you want to load them back in the same shape, here's how:\n",
    "# from starfish.pipeline.features.spot_attributes import SpotAttributes\n",
    "# spot_attributes = [SpotAttributes.load(attrs) for attrs in glob('spot_attributes_c*.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not a very performant function because of how matplotlib renders circles as individual artists, \n",
    "# but I think it's useful for debugging the spot detection.\n",
    "\n",
    "# Note that in places where spots are \"missed\" it is often because they've been localized to individual \n",
    "# nearby z-planes, whereas most spots exist across several layers of z.\n",
    "\n",
    "s.image.show_stack({Indices.CH.value: 1, Indices.ROUND.value: 0}, show_spots=spot_attributes[1][0], figure_size=(20, 20), p_min=60, p_max=99.9);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
