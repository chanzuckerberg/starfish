{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metadata = '/Users/ajc/Desktop/iss_breast_formatted/experiment.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = starfish.Experiment.from_json(experiment_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.fov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.image import Filter\n",
    "from starfish.image import Registration\n",
    "from starfish.spots import SpotFinder\n",
    "import warnings\n",
    "from starfish.image import Segmentation\n",
    "\n",
    "\n",
    "def pipeline(fov): \n",
    "    \n",
    "    primary_image = fov.primary_image\n",
    "\n",
    "    # filter raw data\n",
    "    masking_radius = 15\n",
    "    filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n",
    "    print('WhiteTophat Filtering...')\n",
    "    filt.run(primary_image, verbose=True)\n",
    "        \n",
    "    print('Registering...')\n",
    "    registration = Registration.FourierShiftRegistration(\n",
    "        upsampling=1000,\n",
    "        reference_stack=dots\n",
    "    )\n",
    "    registration.run(primary_image, verbose=True)\n",
    "    \n",
    "    # parameters to define the allowable gaussian sizes (parameter space)\n",
    "    min_sigma = 1\n",
    "    max_sigma = 10\n",
    "    num_sigma = 30\n",
    "    threshold = 0.01\n",
    "\n",
    "    p = SpotFinder.GaussianSpotDetector(\n",
    "        min_sigma=min_sigma,\n",
    "        max_sigma=max_sigma,\n",
    "        num_sigma=num_sigma,\n",
    "        threshold=threshold,\n",
    "        measurement_type='mean',\n",
    "    )\n",
    "\n",
    "    # detect triggers some numpy warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        # blobs = dots; define the spots in the dots image, but then find them again in the stack.\n",
    "        blobs_image = dots.max_proj(Indices.ROUND, Indices.Z)\n",
    "        intensities = p.run(primary_image, blobs_image=blobs_image)\n",
    "        \n",
    "    decoded = experiment.codebook.decode_per_round_max(intensities)\n",
    "    \n",
    "    dapi_thresh = .16  # binary mask for cell (nuclear) locations\n",
    "    stain_thresh = .22  # binary mask for overall cells // binarization of stain\n",
    "    min_dist = 57\n",
    "\n",
    "    stain = np.mean(primary_image.max_proj(Indices.CH, Indices.Z), axis=0)\n",
    "    stain = stain/stain.max()\n",
    "    nuclei_projection = nuclei.max_proj(Indices.ROUND, Indices.CH, Indices.Z)\n",
    "\n",
    "    seg = Segmentation.Watershed(\n",
    "        dapi_threshold=dapi_thresh,\n",
    "        input_threshold=stain_thresh,\n",
    "        min_distance=min_dist\n",
    "    )\n",
    "    regions = seg.run(primary_image, nuclei)\n",
    "    \n",
    "    return decoded, regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}